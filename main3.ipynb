{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "participants = pd.read_csv('Dataset/participants.tsv', sep='\\t')\n",
    "print(participants.head(5))  # To inspect the first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# List of subject IDs (assuming you have filenames like sub-pd01, sub-hc01, etc.)\n",
    "subjects = participants.participant_id # List all subjects here\n",
    "subjects=subjects.to_list()\n",
    "sessions = ['ses-off', 'ses-on']  # for Parkinson's patients, if available\n",
    "\n",
    "print(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# List of subject IDs (assuming you have filenames like sub-pd01, sub-hc01, etc.)\n",
    "subjects = participants.participant_id # List all subjects here\n",
    "subjects=subjects.to_list()\n",
    "sessions = ['ses-off', 'ses-on']  # for Parkinson's patients, if available\n",
    "\n",
    "print(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_files_pd_on=[]\n",
    "subject_files_pd_off=[]\n",
    "subject_files_hc=[]\n",
    "\n",
    "for subject in subjects:\n",
    "    if 'pd' in subject:\n",
    "        for session in sessions:\n",
    "            file_path = f\"Dataset/{subject}/{session}/eeg/{subject}_{session}_task-rest_eeg.bdf\"\n",
    "            if session == 'ses-on':\n",
    "                subject_files_pd_on.append(file_path)\n",
    "            else:\n",
    "                subject_files_pd_off.append(file_path)\n",
    "    elif 'hc' in subject:\n",
    "        session = 'ses-hc'\n",
    "        file_path = f\"Dataset/{subject}/{session}/eeg/{subject}_{session}_task-rest_eeg.bdf\"\n",
    "        subject_files_hc.append(file_path)\n",
    "\n",
    "print(subject_files_pd_on)\n",
    "print(subject_files_pd_off)\n",
    "print(subject_files_hc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_montage(raw_data):\n",
    "    montage = mne.channels.make_standard_montage('biosemi32')\n",
    "    raw_data.set_montage(montage, on_missing='warn')\n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass_filter(raw_data, l_freq=0.5, h_freq=50.0):\n",
    "    raw_data.filter(l_freq=l_freq, h_freq=h_freq)\n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use T7 or T8 as proxy ECG channels (experimental approach)\n",
    "def find_ecg_via_temporal_channels(ica, raw_data):\n",
    "    # Experimentally identify ECG-like artifacts using temporal channels\n",
    "    ecg_indices, ecg_scores = ica.find_bads_ecg(raw_data, ch_name='T7')\n",
    "    ica.exclude += ecg_indices  # Exclude identified ECG-like components\n",
    "    return ica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.preprocessing import ICA\n",
    "def apply_ica(raw_data, n_components=32):\n",
    "    ica = ICA(n_components=n_components, random_state=97, max_iter=\"auto\")\n",
    "    ica.fit(raw_data)\n",
    "    \n",
    "    # Detect artifacts\n",
    "    eog_indices, _ = ica.find_bads_eog(raw_data,ch_name=['Fp2', 'F8'],threshold=1.96)  # Detect eye blink components\n",
    "    \n",
    "    # Mark components for removal\n",
    "    ica.exclude = eog_indices\n",
    "    # Experimental ECG detection\n",
    "    ica = find_ecg_via_temporal_channels(ica, raw_data)\n",
    "    \n",
    "    # Apply ICA to remove artifacts\n",
    "    raw_data = ica.apply(raw_data)\n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_data(raw_data, duration=1.0):\n",
    "    events = mne.make_fixed_length_events(raw_data, duration=duration)\n",
    "    epochs = mne.Epochs(raw_data, events, tmin=0, tmax=duration, baseline=None, preload=True)\n",
    "    eeg_data = epochs.get_data()  # Shape should be (180, 32, 512) if 3 mins, 32 channels, 512 samples/s\n",
    "    return eeg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define frequency bands\n",
    "freq_bands = {\n",
    "    \"delta\": (1, 4),\n",
    "    \"theta\": (4, 8),\n",
    "    \"alpha\": (8, 12),\n",
    "    \"beta\": (13, 30),\n",
    "    \"gamma\": (30, 48)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_psd(eeg_data, sfreq):\n",
    "    psd_features = {}\n",
    "    for band, (low, high) in freq_bands.items():\n",
    "        psd_band, _ = mne.time_frequency.psd_array_multitaper(\n",
    "            eeg_data, sfreq=sfreq, fmin=low, fmax=high, adaptive=True, normalization='full'\n",
    "        )\n",
    "        psd_features[band] = psd_band.mean(axis=2)  # Average PSD across time\n",
    "    return psd_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to process a single subject and extract PSD features\n",
    "def process_subject(raw_data, sfreq):\n",
    "    # Apply bandpass filtering and artifact removal here as per previous preprocessing steps\n",
    "    set_montage(raw_data)\n",
    "    raw_filtered = bandpass_filter(raw_data)  # Assuming bandpass_filter function is defined\n",
    "    raw_filtered = apply_ica(raw_filtered)\n",
    "    epochs = segment_data(raw_filtered)  # Assuming segment_data function is defined to get (180, 32, 512)\n",
    "    eeg_data = epochs[:, :, :512]  # Shape (180, 32, 512)\n",
    "\n",
    "    # Compute PSD features for this subject\n",
    "    psd_features = compute_psd(eeg_data, sfreq)  # Dictionary with PSD for each frequency band\n",
    "    return psd_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all subjects and store PSD features\n",
    "def collect_psd_features(subject_files, sfreq):\n",
    "    all_psd_features = {'delta': [], 'theta': [], 'alpha': [], 'beta': [], 'gamma': []}\n",
    "    for subject_file in subject_files:\n",
    "        # Load subject's data\n",
    "        raw_data = mne.io.read_raw_bdf(subject_file, preload=True)\n",
    "        raw_data.crop(tmax=180.)\n",
    "        raw_data = raw_data.drop_channels(['EXG1', 'EXG2', 'EXG3', 'EXG4', 'EXG5', 'EXG6', 'EXG7', 'EXG8', 'Status'])\n",
    "        # Process each subject's data to extract PSD features\n",
    "        psd_features = process_subject(raw_data, sfreq)\n",
    "        print(\"Shape of psd_features[delta] in each sub: \",np.asarray(psd_features['delta']).shape)\n",
    "        # Append features for each frequency band\n",
    "        for band in all_psd_features.keys():\n",
    "            all_psd_features[band].append(psd_features[band])  # Each entry: (180, 32)\n",
    "    return all_psd_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each subject’s PSD feature for the δ band should have a shape of \n",
    "180\n",
    "×\n",
    "32\n",
    "180×32 (180 time samples, 32 channels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect PSD features for each group\n",
    "sfreq = 512  # Sample frequency as given"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For PD_on or PD_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_features_pd = collect_psd_features(subject_files_pd_on, sfreq)\n",
    "# psd_features_pd = collect_psd_features(subject_files_pd_off, sfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(psd_features_pd['delta']).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_features_hc = collect_psd_features(subject_files_hc, sfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(psd_features_hc['delta']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine PSD features into a dataset for SVM classification\n",
    "psd_features = {'delta': psd_features_pd['delta'] + psd_features_hc['delta'],\n",
    "                'theta': psd_features_pd['theta'] + psd_features_hc['theta'],\n",
    "                'alpha': psd_features_pd['alpha'] + psd_features_hc['alpha'],\n",
    "                'beta': psd_features_pd['beta'] + psd_features_hc['beta'],\n",
    "                'gamma': psd_features_pd['gamma'] + psd_features_hc['gamma']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(psd_features['delta']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset (example: delta band, label 0 for HC and 1 for PD_ON,OFF)\n",
    "def prepare_dataset(psd_features, num_pd=15, num_hc=16, label_pd=1, label_hc=0):\n",
    "    # Combine PSD features for PD_ON and HC\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    # Append PD subjects\n",
    "    for i in range(num_pd):\n",
    "        psd_pd_on_off = psd_features['delta'][i]  # Shape (180, 32)\n",
    "        data.append(psd_pd_on_off)\n",
    "        labels.extend([label_pd] * psd_pd_on_off.shape[0])  # Label each sample in this subject's data as PD_ON\n",
    "    \n",
    "    # Append HC subjects\n",
    "    for i in range(num_hc):\n",
    "        psd_hc = psd_features['delta'][i + num_pd]  # Assuming next in sequence\n",
    "        data.append(psd_hc)\n",
    "        labels.extend([label_hc] * psd_hc.shape[0])  # Label each sample in this subject's data as HC\n",
    "    \n",
    "    # Stack data into final dataset\n",
    "    data = np.vstack(data)  # Resulting shape: (5580, 32)\n",
    "    labels = np.array(labels)  # Resulting shape: (5580,)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset (using only δ band for this example)\n",
    "data, labels = prepare_dataset({'delta': psd_features['delta']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the data shape\n",
    "print(\"Full dataset shape:\", data.shape)  # Should be (5580, 32)\n",
    "print(\"Label distribution:\", np.unique(labels, return_counts=True))  # Should show counts for PD_ON and HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save using pickle\n",
    "with open('new_data/pd_on vs hc/delta.pkl', 'wb') as f:\n",
    "    pickle.dump(\n",
    "        {\n",
    "            'data': data, \n",
    "            'labels': labels\n",
    "        },\n",
    "    f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
