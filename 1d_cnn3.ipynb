{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load data from each band (assuming files are named accordingly)\n",
    "# with open('new_data/pd_off vs hc/delta.pkl', 'rb') as f:\n",
    "#     delta_data = pickle.load(f)['data']\n",
    "# with open('new_data/pd_off vs hc/theta.pkl', 'rb') as f:\n",
    "#     theta_data = pickle.load(f)['data']\n",
    "# with open('new_data/pd_off vs hc/alpha.pkl', 'rb') as f:\n",
    "#     alpha_data = pickle.load(f)['data']\n",
    "# with open('new_data/pd_off vs hc/beta.pkl', 'rb') as f:\n",
    "#     beta_data = pickle.load(f)['data']\n",
    "# with open('new_data/pd_off vs hc/gamma.pkl', 'rb') as f:\n",
    "#     gamma_data = pickle.load(f)['data']\n",
    "\n",
    "# # Load labels (assume the labels are the same for each band)\n",
    "# with open('new_data/pd_off vs hc/delta.pkl', 'rb') as f:\n",
    "#     labels = pickle.load(f)['labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from each band (assuming files are named accordingly)\n",
    "with open('IowaDataset/processed/delta.pkl', 'rb') as f:\n",
    "    delta_data = pickle.load(f)['data']\n",
    "with open('IowaDataset/processed/theta.pkl', 'rb') as f:\n",
    "    theta_data = pickle.load(f)['data']\n",
    "with open('IowaDataset/processed/alpha.pkl', 'rb') as f:\n",
    "    alpha_data = pickle.load(f)['data']\n",
    "with open('IowaDataset/processed/beta.pkl', 'rb') as f:\n",
    "    beta_data = pickle.load(f)['data']\n",
    "with open('IowaDataset/processed/gamma.pkl', 'rb') as f:\n",
    "    gamma_data = pickle.load(f)['data']\n",
    "\n",
    "\n",
    "# Load labels (assume the labels are the same for each band)\n",
    "with open('IowaDataset/processed/gamma.pkl', 'rb') as f:\n",
    "    labels = pickle.load(f)['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=delta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3360, 29)\n",
      "(3360,)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.541414077285762e-12"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[7][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.log1p(data * 1e15)  # log(1 + x) to prevent log(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.052798925675562"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[7][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.1, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3024, 29)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Fold 1/5...\n",
      "Epoch 1/10\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.7517 - accuracy: 0.5147 - val_loss: 0.6845 - val_accuracy: 0.5355\n",
      "Epoch 2/10\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6824 - accuracy: 0.5672 - val_loss: 0.6662 - val_accuracy: 0.6860\n",
      "Epoch 3/10\n",
      "76/76 [==============================] - 0s 6ms/step - loss: 0.6596 - accuracy: 0.6019 - val_loss: 0.6012 - val_accuracy: 0.7091\n",
      "Epoch 4/10\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5762 - accuracy: 0.6900 - val_loss: 0.4878 - val_accuracy: 0.7504\n",
      "Epoch 5/10\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5001 - accuracy: 0.7288 - val_loss: 0.4143 - val_accuracy: 0.8050\n",
      "Epoch 6/10\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.7788 - val_loss: 0.3560 - val_accuracy: 0.8083\n",
      "Epoch 7/10\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8041 - val_loss: 0.3321 - val_accuracy: 0.8397\n",
      "Epoch 8/10\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.3784 - accuracy: 0.8016 - val_loss: 0.3227 - val_accuracy: 0.8479\n",
      "Epoch 9/10\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.3599 - accuracy: 0.8260 - val_loss: 0.3135 - val_accuracy: 0.8512\n",
      "Epoch 10/10\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.3445 - accuracy: 0.8227 - val_loss: 0.3006 - val_accuracy: 0.8545\n",
      "Fold 1 Accuracy: 0.8545\n",
      "\n",
      "Training Fold 2/5...\n",
      "Epoch 1/10\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.7318 - accuracy: 0.5337 - val_loss: 0.6851 - val_accuracy: 0.6132\n",
      "Epoch 2/10\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6863 - accuracy: 0.5461 - val_loss: 0.6512 - val_accuracy: 0.7273\n",
      "Epoch 3/10\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6163 - accuracy: 0.6457 - val_loss: 0.5335 - val_accuracy: 0.7223\n",
      "Epoch 4/10\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.5399 - accuracy: 0.7119 - val_loss: 0.4547 - val_accuracy: 0.7570\n",
      "Epoch 5/10\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.4755 - accuracy: 0.7433 - val_loss: 0.3945 - val_accuracy: 0.7983\n",
      "Epoch 6/10\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.7739 - val_loss: 0.3591 - val_accuracy: 0.8165\n",
      "Epoch 7/10\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.3769 - accuracy: 0.8115 - val_loss: 0.3370 - val_accuracy: 0.8496\n",
      "Epoch 8/10\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.3753 - accuracy: 0.8094 - val_loss: 0.3126 - val_accuracy: 0.8496\n",
      "Epoch 9/10\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.3565 - accuracy: 0.8255 - val_loss: 0.3006 - val_accuracy: 0.8727\n",
      "Epoch 10/10\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.3507 - accuracy: 0.8160 - val_loss: 0.2989 - val_accuracy: 0.8479\n",
      "Fold 2 Accuracy: 0.8479\n",
      "\n",
      "Training Fold 3/5...\n",
      "Epoch 1/10\n",
      "76/76 [==============================] - 1s 6ms/step - loss: 0.7887 - accuracy: 0.5138 - val_loss: 0.6767 - val_accuracy: 0.6926\n",
      "Epoch 2/10\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6852 - accuracy: 0.5473 - val_loss: 0.6471 - val_accuracy: 0.6992\n",
      "Epoch 3/10\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6475 - accuracy: 0.6180 - val_loss: 0.5672 - val_accuracy: 0.7190\n",
      "Epoch 4/10\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5674 - accuracy: 0.6862 - val_loss: 0.4793 - val_accuracy: 0.7372\n",
      "Epoch 5/10\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.4931 - accuracy: 0.7156 - val_loss: 0.3875 - val_accuracy: 0.7818\n",
      "Epoch 6/10\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.7635 - val_loss: 0.3541 - val_accuracy: 0.8149\n",
      "Epoch 7/10\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.7788 - val_loss: 0.3332 - val_accuracy: 0.8248\n",
      "Epoch 8/10\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.3833 - accuracy: 0.8049 - val_loss: 0.3140 - val_accuracy: 0.8364\n",
      "Epoch 9/10\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.3643 - accuracy: 0.8206 - val_loss: 0.3029 - val_accuracy: 0.8479\n",
      "Epoch 10/10\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.3516 - accuracy: 0.8169 - val_loss: 0.2904 - val_accuracy: 0.8529\n",
      "Fold 3 Accuracy: 0.8529\n",
      "\n",
      "Training Fold 4/5...\n",
      "Epoch 1/10\n",
      "76/76 [==============================] - 1s 7ms/step - loss: 0.7436 - accuracy: 0.5275 - val_loss: 0.6871 - val_accuracy: 0.5438\n",
      "Epoch 2/10\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6922 - accuracy: 0.5527 - val_loss: 0.6749 - val_accuracy: 0.6628\n",
      "Epoch 3/10\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6776 - accuracy: 0.5610 - val_loss: 0.6480 - val_accuracy: 0.6959\n",
      "Epoch 4/10\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6382 - accuracy: 0.6259 - val_loss: 0.5320 - val_accuracy: 0.7405\n",
      "Epoch 5/10\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5443 - accuracy: 0.7131 - val_loss: 0.4178 - val_accuracy: 0.7851\n",
      "Epoch 6/10\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7619 - val_loss: 0.3601 - val_accuracy: 0.8347\n",
      "Epoch 7/10\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.7954 - val_loss: 0.3357 - val_accuracy: 0.8380\n",
      "Epoch 8/10\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.3963 - accuracy: 0.7995 - val_loss: 0.3337 - val_accuracy: 0.8331\n",
      "Epoch 9/10\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.3727 - accuracy: 0.8169 - val_loss: 0.3114 - val_accuracy: 0.8628\n",
      "Epoch 10/10\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.3554 - accuracy: 0.8284 - val_loss: 0.2916 - val_accuracy: 0.8645\n",
      "Fold 4 Accuracy: 0.8645\n",
      "\n",
      "Training Fold 5/5...\n",
      "Epoch 1/10\n",
      "76/76 [==============================] - 1s 6ms/step - loss: 0.7234 - accuracy: 0.5132 - val_loss: 0.6855 - val_accuracy: 0.5248\n",
      "Epoch 2/10\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.6897 - accuracy: 0.5475 - val_loss: 0.6785 - val_accuracy: 0.6722\n",
      "Epoch 3/10\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.6683 - accuracy: 0.5814 - val_loss: 0.6184 - val_accuracy: 0.7185\n",
      "Epoch 4/10\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.5831 - accuracy: 0.6690 - val_loss: 0.4866 - val_accuracy: 0.7219\n",
      "Epoch 5/10\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.7405 - val_loss: 0.4221 - val_accuracy: 0.7599\n",
      "Epoch 6/10\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7669 - val_loss: 0.3658 - val_accuracy: 0.8063\n",
      "Epoch 7/10\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.3906 - accuracy: 0.7934 - val_loss: 0.3550 - val_accuracy: 0.8444\n",
      "Epoch 8/10\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.3716 - accuracy: 0.8136 - val_loss: 0.3220 - val_accuracy: 0.8361\n",
      "Epoch 9/10\n",
      "76/76 [==============================] - 0s 5ms/step - loss: 0.3414 - accuracy: 0.8277 - val_loss: 0.3093 - val_accuracy: 0.8709\n",
      "Epoch 10/10\n",
      "76/76 [==============================] - 0s 4ms/step - loss: 0.3473 - accuracy: 0.8264 - val_loss: 0.3152 - val_accuracy: 0.8328\n",
      "Fold 5 Accuracy: 0.8328\n"
     ]
    }
   ],
   "source": [
    "# Define K-Fold cross-validation\n",
    "k = 5  # Number of folds\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Convert data into NumPy arrays (ensure they are properly formatted)\n",
    "X = np.array(X_train).reshape(X_train.shape[0], X_train.shape[1], 1)  # Reshape for 1D-CNN\n",
    "y = np.array(y_train)\n",
    "\n",
    "# Store accuracy for each fold\n",
    "fold_accuracies = []\n",
    "\n",
    "# K-Fold Training Loop\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "    print(f\"\\nTraining Fold {fold + 1}/{k}...\")\n",
    "\n",
    "    # Split data\n",
    "    X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "    y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "\n",
    "    # Define a fresh model for each fold\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(29, 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n",
    "    ])\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train model\n",
    "    history = model.fit(X_train_fold, y_train_fold, epochs=10, batch_size=32, \n",
    "                        validation_data=(X_val_fold, y_val_fold), verbose=1)\n",
    "\n",
    "    # Evaluate model on validation set\n",
    "    val_loss, val_acc = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
    "    print(f\"Fold {fold + 1} Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    # Store accuracy\n",
    "    fold_accuracies.append(val_acc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Accuracy across 5 folds: 0.8505 ± 0.0104\n"
     ]
    }
   ],
   "source": [
    "# Print average accuracy\n",
    "print(f\"\\nAverage Accuracy across {k} folds: {np.mean(fold_accuracies):.4f} ± {np.std(fold_accuracies):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
