{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from mne.preprocessing import ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "subject_pd=['PD1001','PD1021','PD1031','PD1061','PD1091','PD1101','PD1151'\n",
    "                    ,'PD1201','PD1251','PD1261','PD1311','PD1571','PD1661','PD1681']\n",
    "subject_hc=['Control1021','Control1041','Control1061','Control1081','Control1101'\n",
    "                ,'Control1111','Control1191','Control1201','Control1211','Control1231','Control1291'\n",
    "                ,'Control1351','Control1381','Control1411']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_files_pd=[]\n",
    "subject_files_hc=[]\n",
    "\n",
    "for subject in subject_pd:\n",
    "    file_path = f\"IowaDataset/Raw data/{subject}.vhdr\"\n",
    "    subject_files_pd.append(file_path)\n",
    "\n",
    "for subject in subject_hc:\n",
    "    file_path = f\"IowaDataset/Raw data/{subject}.vhdr\"\n",
    "    subject_files_hc.append(file_path)\n",
    "\n",
    "print(subject_files_pd)\n",
    "print(subject_files_hc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(subject_files_pd))\n",
    "print(len(subject_files_hc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_montage(raw_data):\n",
    "    montage = mne.channels.make_standard_montage('biosemi32')\n",
    "    raw_data.set_montage(montage, on_missing='warn')\n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass_filter(raw_data, l_freq=0.5, h_freq=50.0):\n",
    "    raw_data.filter(l_freq=l_freq, h_freq=h_freq)\n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ecg_via_temporal_channels(ica, raw_data):\n",
    "    # Experimentally identify ECG-like artifacts using temporal channels\n",
    "    ecg_indices, ecg_scores = ica.find_bads_ecg(raw_data, ch_name='T7')\n",
    "    ica.exclude += ecg_indices  # Exclude identified ECG-like components\n",
    "    return ica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_data(raw_data, duration=1.0):\n",
    "    events = mne.make_fixed_length_events(raw_data, duration=duration)\n",
    "    epochs = mne.Epochs(raw_data, events, tmin=0, tmax=duration, baseline=None, preload=True)\n",
    "    eeg_data = epochs.get_data()  # Shape should be (180, 32, 512) if 3 mins, 32 channels, 512 samples/s\n",
    "    return eeg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ica(raw_data, n_components=29):\n",
    "    ica = ICA(n_components=n_components, random_state=97, max_iter=\"auto\")\n",
    "    ica.fit(raw_data)\n",
    "    \n",
    "    # Detect artifacts\n",
    "    eog_indices, _ = ica.find_bads_eog(raw_data,ch_name=['Fp2', 'F8'],threshold=1.96)  # Detect eye blink components\n",
    "    \n",
    "    # Mark components for removal\n",
    "    ica.exclude = eog_indices\n",
    "    # Experimental ECG detection\n",
    "    ica = find_ecg_via_temporal_channels(ica, raw_data)\n",
    "    \n",
    "    # Apply ICA to remove artifacts\n",
    "    raw_data = ica.apply(raw_data)\n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define frequency bands\n",
    "freq_bands = {\n",
    "    \"delta\": (1, 4),\n",
    "    \"theta\": (4, 8),\n",
    "    \"alpha\": (8, 12),\n",
    "    \"beta\": (13, 30),\n",
    "    \"gamma\": (30, 48)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_psd(eeg_data, sfreq):\n",
    "    psd_features = {}\n",
    "    for band, (low, high) in freq_bands.items():\n",
    "        psd_band, _ = mne.time_frequency.psd_array_multitaper(\n",
    "            eeg_data, sfreq=sfreq, fmin=low, fmax=high, adaptive=True, normalization='full'\n",
    "        )\n",
    "        psd_features[band] = psd_band.mean(axis=2)  # Average PSD across time\n",
    "    return psd_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to process a single subject and extract PSD features\n",
    "def process_subject(raw_data, sfreq):\n",
    "    # Apply bandpass filtering and artifact removal here as per previous preprocessing steps\n",
    "    set_montage(raw_data)\n",
    "    raw_filtered = bandpass_filter(raw_data)  # Assuming bandpass_filter function is defined\n",
    "    raw_filtered = apply_ica(raw_filtered)\n",
    "    epochs = segment_data(raw_filtered)  # Assuming segment_data function is defined to get (180, 32, 512)\n",
    "    eeg_data = epochs[:,:29, :500]  # Shape (180, 29, 500)\n",
    "\n",
    "    # Compute PSD features for this subject\n",
    "    psd_features = compute_psd(eeg_data, sfreq)  # Dictionary with PSD for each frequency band\n",
    "    return psd_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_psd_features(subject_files, sfreq):\n",
    "    all_psd_features = {'delta': [], 'theta': [], 'alpha': [], 'beta': [], 'gamma': []}\n",
    "    for subject_file in subject_files:\n",
    "        # Load subject's data\n",
    "        raw_data = mne.io.read_raw_brainvision(subject_file, preload=True)\n",
    "        raw_data.crop(tmax=120.)\n",
    "\n",
    "        channels_to_keep = ['Fp1', 'AF3', 'F7', 'F3', 'FC1', 'FC5', 'T7', 'C3', \n",
    "                            'CP1', 'CP5', 'P7', 'P3', 'O1', 'Oz', 'O2', \n",
    "                            'P4', 'P8', 'CP6', 'CP2', 'C4', 'T8', 'FC6', 'FC2', \n",
    "                            'F4', 'F8', 'AF4', 'Fp2', 'Fz', 'Cz']\n",
    "        raw_data = raw_data.pick_channels(channels_to_keep)\n",
    "        # 29 channles\n",
    "        \n",
    "        # Process each subject's data to extract PSD features\n",
    "        psd_features = process_subject(raw_data, sfreq)\n",
    "        print(\"Shape of psd_features[delta] in each sub: \",np.asarray(psd_features['delta']).shape)\n",
    "        # Append features for each frequency band\n",
    "        for band in all_psd_features.keys():\n",
    "            all_psd_features[band].append(psd_features[band])  # Each entry: (180, 32)\n",
    "    return all_psd_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfreq = 500  # Sample frequency as given\n",
    "\n",
    "# psd_features_pd = collect_psd_features(subject_files_pd_on, sfreq)\n",
    "psd_features_pd = collect_psd_features(subject_files_pd, sfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(psd_features_pd['beta']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_features_hc = collect_psd_features(subject_files_hc, sfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(psd_features_hc['delta']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine PSD features into a dataset for SVM classification\n",
    "psd_features = {'delta': psd_features_pd['delta'] + psd_features_hc['delta'],\n",
    "                'theta': psd_features_pd['theta'] + psd_features_hc['theta'],\n",
    "                'alpha': psd_features_pd['alpha'] + psd_features_hc['alpha'],\n",
    "                'beta': psd_features_pd['beta'] + psd_features_hc['beta'],\n",
    "                'gamma': psd_features_pd['gamma'] + psd_features_hc['gamma']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(psd_features['delta']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset (example: delta band, label 0 for HC and 1 for PD_ON,OFF)\n",
    "def prepare_dataset(psd_features, num_pd=14, num_hc=14, label_pd=1, label_hc=0):\n",
    "    # Combine PSD features for PD_ON and HC\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    # Append PD subjects\n",
    "    for i in range(num_pd):\n",
    "        psd_pd_on_off = psd_features['gamma'][i]  # Shape (180, 32)\n",
    "        data.append(psd_pd_on_off)\n",
    "        labels.extend([label_pd] * psd_pd_on_off.shape[0])  # Label each sample in this subject's data as PD_ON\n",
    "    \n",
    "    # Append HC subjects\n",
    "    for i in range(num_hc):\n",
    "        psd_hc = psd_features['gamma'][i + num_pd]  # Assuming next in sequence\n",
    "        data.append(psd_hc)\n",
    "        labels.extend([label_hc] * psd_hc.shape[0])  # Label each sample in this subject's data as HC\n",
    "    \n",
    "    # Stack data into final dataset\n",
    "    data = np.vstack(data)  # Resulting shape: (5580, 32)\n",
    "    labels = np.array(labels)  # Resulting shape: (5580,)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset (using only δ band for this example)\n",
    "data, labels = prepare_dataset({'gamma': psd_features['gamma']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the data shape\n",
    "print(\"Full dataset shape:\", data.shape)  # Should be (5580, 32)\n",
    "print(\"Label distribution:\", np.unique(labels, return_counts=True))  # Should show counts for PD_ON and HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save using pickle\n",
    "with open('IowaDataset/processed/gamma.pkl', 'wb') as f:\n",
    "    pickle.dump(\n",
    "        {\n",
    "            'data': data, \n",
    "            'labels': labels\n",
    "        },\n",
    "    f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
